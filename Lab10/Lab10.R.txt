#Heirarchical Clustering

#1.Load the necessary packages for clustering
#install.packages("tidyverse")
#install.packages("cluster")
#install.packages("factoextra")
#install.packages("dendextend")

library(tidyverse)  # data manipulation
library(cluster)    # clustering algorithms
library(factoextra) # clustering visualization
library(dendextend) # for comparing two dendrograms

#Hierarchical Clustering Algorithms
## Agglomerative Clustering
## Divisive hierarchical clustering

#Reading file
df <- USArrests
df <- na.omit(df)
head(df)

#3. Scaling/Standardizing
df <- scale(df)
head(df)

#4. Perform Agglomerative Hierarchical Clustering by computing dissimilarity
#values and perform any hierarchical clustering method like complete linkage and
#then plot the dendogram.

##Agglomerative
# Dissimilarity matrix
d <- dist(df, method = "euclidean")
# Hierarchical clustering using Complete Linkage
hc1 <- hclust(d, method = "complete" )
# Plot the obtained dendrogram
plot(hc1, cex = 0.6, hang = -1, main="Dendogram")

#5.Determine optimal number of clusters
# methods to assess
m <- c( "average", "single", "complete", "ward")
names(m) <- c( "average", "single", "complete", "ward")

# function to compute coefficient
ac <- function(x) {
  agnes(df, method = x)$ac
}

map_dbl(m, ac)